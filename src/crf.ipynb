{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "from crf import *\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(\"\"))\n",
    "\n",
    "train_data_tokens = load_tokens(os.path.join(ROOT_DIR, \"data\", \"training_data_tokens.json\"))\n",
    "train_data = json.load(open(os.path.join(ROOT_DIR, \"data\", \"training_data.json\"), \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bio = create_bio_tags(train_data, train_data_tokens)\n",
    "with open(os.path.join(ROOT_DIR, \"data\", \"training_data_bio.json\"), \"w\") as f:\n",
    "\tjson.dump(train_data_bio, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CRF(\n",
    "\tmodel_path=os.path.join(ROOT_DIR, \"models\", \"crf_0_0.crfsuite\"),\n",
    "\ttrainer_params={\n",
    "\t\t'c1': 1e-3,\n",
    "\t\t'c2': 1e-1,\n",
    "\t\t'max_iterations': 50,\n",
    "\t\t\"padding\": True,\n",
    "\t\t\"before_lim\": 6,\n",
    "\t\t\"after_lim\": 1,\n",
    "\t},\n",
    "\tverbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:31<00:00,  8.16it/s]\n"
     ]
    }
   ],
   "source": [
    "precompute_pos(\n",
    "\ttokens_path=os.path.join(ROOT_DIR, \"data\", \"training_data_tokens.json\"),\n",
    "\tpos_path=os.path.join(ROOT_DIR, \"data\", \"training_data_pos.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:00<00:00, 3330.11it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "\ttrain_tokens_path=os.path.join(ROOT_DIR, \"data\", \"training_data_tokens.json\"),\n",
    "\ttrain_labels_path=os.path.join(ROOT_DIR, \"data\", \"training_data_bio.json\"),\n",
    "\ttrain_pos_path=os.path.join(ROOT_DIR, \"data\", \"training_data_pos.json\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['diverticulosis', 'extenso', 'insuficiencia', 'renal', 'cronico',\n",
       "        'colelitiasis', 'antecedente', 'quirurgico', 'exeresis', 'de',\n",
       "        'lesión', 'cutanea', 'con', 'anestesia', 'local', 'protesis',\n",
       "        'total', 'de', 'cadera', 'cordectomia', 'herniorrafia', 'inguinal',\n",
       "        'proz', 'actual', 'var', 'de', '81a', 'que', 'a', 'raiz', 'de',\n",
       "        'episodio', 'de', 'hematuria', 'macroscopico', 'él', 'realizar',\n",
       "        'cistoscopia', 'que', 'ser', 'negativo', 'para', 'lesión',\n",
       "        'maligno', 'pero', 'él', 'objetiir', 'estenosis', 'de', 'uretro'],\n",
       "       dtype='<U14'),\n",
       " array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "        'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "        'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-NEG',\n",
       "        'O', 'O', 'B-NEG', 'I-NEG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       "       dtype='<U5'),\n",
       " array([[558, 572],\n",
       "        [573, 580],\n",
       "        [581, 594],\n",
       "        [595, 600],\n",
       "        [601, 608],\n",
       "        [609, 621],\n",
       "        [622, 634],\n",
       "        [635, 646],\n",
       "        [648, 656],\n",
       "        [657, 659],\n",
       "        [660, 668],\n",
       "        [669, 677],\n",
       "        [678, 681],\n",
       "        [682, 691],\n",
       "        [692, 697],\n",
       "        [698, 706],\n",
       "        [707, 712],\n",
       "        [713, 715],\n",
       "        [716, 722],\n",
       "        [723, 734],\n",
       "        [735, 747],\n",
       "        [748, 756],\n",
       "        [757, 763],\n",
       "        [764, 770],\n",
       "        [771, 776],\n",
       "        [777, 779],\n",
       "        [780, 783],\n",
       "        [784, 787],\n",
       "        [788, 789],\n",
       "        [790, 794],\n",
       "        [795, 797],\n",
       "        [798, 806],\n",
       "        [807, 809],\n",
       "        [810, 819],\n",
       "        [820, 832],\n",
       "        [833, 835],\n",
       "        [836, 843],\n",
       "        [844, 855],\n",
       "        [856, 859],\n",
       "        [860, 862],\n",
       "        [863, 871],\n",
       "        [872, 876],\n",
       "        [877, 885],\n",
       "        [886, 894],\n",
       "        [895, 899],\n",
       "        [900, 902],\n",
       "        [903, 911],\n",
       "        [912, 921],\n",
       "        [922, 924],\n",
       "        [925, 931]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_sent = train_data_tokens[0][4]\n",
    "ex_sent[\"tokens\"], np.array(model.predict(ex_sent[\"tokens\"])), ex_sent[\"spans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:03<00:00, 77.76it/s]\n"
     ]
    }
   ],
   "source": [
    "model.process(\n",
    "\tdata_path=os.path.join(ROOT_DIR, \"data\", \"training_data.json\"),\n",
    "\ttokens_path=os.path.join(ROOT_DIR, \"data\", \"training_data_tokens.json\"),\n",
    "\tsave_path=os.path.join(ROOT_DIR, \"data\", \"training_data_predictions_crf.json\"),\n",
    "\tpos_path=os.path.join(ROOT_DIR, \"data\", \"training_data_pos.json\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Precision: 0.9330407646862721, Recall:0.9330407646862721, F1:0.9330407646862721\n"
     ]
    }
   ],
   "source": [
    "from eval import EvalOfficial\n",
    "\n",
    "with open(os.path.join(ROOT_DIR, \"data\", 'training_data.json'), 'r', encoding='utf8') as _f:\n",
    "\ttrain_data = json.load(_f)\n",
    "\n",
    "with open(os.path.join(ROOT_DIR, \"data\", 'training_data_predictions_crf.json'), 'r', encoding='utf8') as _f:\n",
    "\ttrain_data_predictions = json.load(_f)\n",
    "\n",
    "metric = EvalOfficial()\n",
    "p, r, f1 = metric.calc(train_data_predictions, train_data)\n",
    "print(\"Training\")\n",
    "print(f'Precision: {p}, Recall:{r}, F1:{f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:11<00:00,  5.62it/s]\n"
     ]
    }
   ],
   "source": [
    "model.process(\n",
    "\tdata_path=os.path.join(ROOT_DIR, \"data\", \"test_data.json\"),\n",
    "\ttokens_path=os.path.join(ROOT_DIR, \"data\", \"test_data_tokens.json\"),\n",
    "\tsave_path=os.path.join(ROOT_DIR, \"data\", \"test_data_predictions_crf.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "Precision: 0.9281980567308247, Recall:0.9281980567308247, F1:0.9281980567308247\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(ROOT_DIR, \"data\", 'test_data.json'), 'r', encoding='utf8') as _f:\n",
    "\ttest_data = json.load(_f)\n",
    "\n",
    "with open(os.path.join(ROOT_DIR, \"data\", 'test_data_predictions_crf.json'), 'r', encoding='utf8') as _f:\n",
    "\ttest_data_predictions = json.load(_f)\n",
    "\n",
    "metric = EvalOfficial()\n",
    "p, r, f1 = metric.calc(test_data_predictions, test_data)\n",
    "print(\"Testing\")\n",
    "print(f'Precision: {p}, Recall:{r}, F1:{f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
