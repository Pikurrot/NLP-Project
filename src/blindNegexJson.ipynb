{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json, os\n",
    "\n",
    "def read_negations(file_path):\n",
    "    negations = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            negation, tag = line.strip().split('\\t\\t')\n",
    "            negations[negation] = tag\n",
    "    return negations\n",
    "\n",
    "def new_tag(start, end, labels, id):\n",
    "    return {'value': {'start': start, 'end': end, 'labels': labels}, 'id': 'ent'+str(id), 'from_name': 'label', 'to_name': 'text', 'type': 'labels'}\n",
    "\n",
    "def fordward_scope(tagged_text, start_index):\n",
    "    end_index = start_index\n",
    "    tagger_checker = tagged_text[end_index]\n",
    "    \n",
    "    # Loop until \".\" is found or end of tagged_sentence\n",
    "    while tagger_checker !=\".\" and end_index != len(tagged_text)-1:\n",
    "        end_index += 1\n",
    "        tagger_checker = tagged_text[end_index]\n",
    "    \n",
    "    return end_index -1\n",
    "\n",
    "def backward_scope(tagged_text, end_index):\n",
    "    start_index = end_index\n",
    "    tagger_checker = tagged_text[start_index]\n",
    "    # Loop until \".\" is found or beginning of tagged_sentence\n",
    "    while tagger_checker != \".\" and start_index != 0:\n",
    "        start_index -= 1\n",
    "        tagger_checker = tagged_text[start_index]\n",
    "\n",
    "        if(tagger_checker==\".\"): start_index + 1\n",
    "\n",
    "    return start_index \n",
    "\n",
    "def tag_negations(text, negations):\n",
    "    result=[]\n",
    "    negations_of_the_text=dict()\n",
    "    for negation in negations:\n",
    "        pattern = r'\\b' + re.escape(negation) + r'\\b'\n",
    "        if re.search(pattern, text):\n",
    "            tag = negations[negation]\n",
    "            negations_of_the_text[negation]=tag\n",
    "    i=0\n",
    "    for negation in negations_of_the_text:\n",
    "        pattern = r'\\b' + re.escape(negation) + r'\\b'\n",
    "        tag = negations[negation]\n",
    "        # Find all occurrences of the negation in the tagged_sentence\n",
    "        negation_occurrences = re.finditer(pattern, text)\n",
    "\n",
    "        # Iterate over each occurrence of the negation\n",
    "        \n",
    "        for match in negation_occurrences:\n",
    "            if(tag[-2]==\"P\"):\n",
    "                result.append(new_tag(match.start(), match.end(), ['UNC'], i))\n",
    "            else:\n",
    "                result.append(new_tag(match.start(), match.end(), ['NEG'], i))\n",
    "            \n",
    "            i+=1\n",
    "        \n",
    "        # Find all occurrences of the negation in the tagged_sentence\n",
    "        negation_occurrences = re.finditer(pattern, text)\n",
    "\n",
    "        for match in negation_occurrences:\n",
    "            if tag == '[PREN]':\n",
    "                scope_tag = '[NSCO]'\n",
    "                start_index = match.end()\n",
    "                end_index = fordward_scope(text, start_index)\n",
    "            elif tag == '[PREP]':\n",
    "                scope_tag = '[USCO]'\n",
    "                start_index = match.end()\n",
    "                end_index = fordward_scope(text, start_index)\n",
    "            elif tag == '[POST]':\n",
    "                scope_tag = '[NSCO]'\n",
    "                end_index = match.start() \n",
    "                start_index = backward_scope(text, end_index)\n",
    "            elif tag == '[POSP]':\n",
    "                scope_tag = '[USCO]'\n",
    "                end_index = match.start() \n",
    "                start_index = backward_scope(text, end_index)\n",
    "            result.append(new_tag(start_index, end_index, [scope_tag], i))\n",
    "            i+=1\n",
    "        return result\n",
    "\n",
    "def process_text(data, negations):\n",
    "\n",
    "    copy_json_object=data\n",
    "    for i in range(len(copy_json_object)):\n",
    "        copy_json_object[i][\"predictions\"][0][\"result\"]=[]\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        text=data[i][\"data\"][\"text\"]\n",
    "        result=tag_negations(text, negations)\n",
    "        copy_json_object[i][\"predictions\"][0][\"result\"].extend(result)\n",
    "\n",
    "    with open(\"../data/output_blind_negex.json\", \"w\") as json_file:\n",
    "        json.dump(copy_json_object, json_file)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(\"\"))\n",
    "\n",
    "negations_file = '../data/negation_speculation_word.txt'\n",
    "data = json.load(open(os.path.join(ROOT_DIR, \"data\", \"training_data.json\")))\n",
    "\n",
    "negations = read_negations(negations_file)\n",
    "process_text(data, negations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
