{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f82bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157c8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/training_data.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b88b9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': {'start': 449, 'end': 452, 'labels': ['NEG']},\n",
       "  'id': 'ent0',\n",
       "  'from_name': 'label',\n",
       "  'to_name': 'text',\n",
       "  'type': 'labels'},\n",
       " {'value': {'start': 452, 'end': 468, 'labels': ['NSCO']},\n",
       "  'id': 'ent1',\n",
       "  'from_name': 'label',\n",
       "  'to_name': 'text',\n",
       "  'type': 'labels'},\n",
       " {'value': {'start': 844, 'end': 856, 'labels': ['NSCO']},\n",
       "  'id': 'ent2',\n",
       "  'from_name': 'label',\n",
       "  'to_name': 'text',\n",
       "  'type': 'labels'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"predictions\"][0][\"result\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c480374",
   "metadata": {},
   "source": [
    "### LIST OF NEGATION WORD AND SPECULATION WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f9818b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def extract_words_from_indices(text, word_indices):\n",
    "    extracted_words = []\n",
    "    for start, end in word_indices:\n",
    "        extracted_words.append(text[start:end])\n",
    "    return extracted_words\n",
    "\n",
    "\"\"\"\n",
    "# Example text\n",
    "# text = \"This is a sample text for demonstration purposes.\"\n",
    "\n",
    "# Example word indices (start and end positions of each word)\n",
    "# word_indices = [(0, 4), (5, 7), (8, 9), (10, 16), (17, 21), (22, 25), (26, 39), (40, 48)]\n",
    "\n",
    "# Extract words from text using indices\n",
    "# extracted_words = extract_words_from_indices(text, word_indices)\n",
    "\n",
    "# print(extracted_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e7916b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_from_indices(text, word_indices):\n",
    "    extracted_words = []\n",
    "    for (start, end), nega in word_indices:\n",
    "        word_ap = text[start:end]\n",
    "        word_ap = re.sub(r'[^a-zA-Z ]', '', word_ap)\n",
    "        # Remove trailing spaces\n",
    "        word_ap = word_ap.rstrip()\n",
    "        # Remove leading spaces\n",
    "        word_ap = word_ap.lstrip()\n",
    "        word_ap = str(word_ap) + \"\\t\\t\" + str(nega)\n",
    "        # print(word_ap)\n",
    "        extracted_words.append(word_ap)\n",
    "    return extracted_words\n",
    "\n",
    "# Example text\n",
    "# text = \"This is a sample text for demonstration purposes.\"\n",
    "\n",
    "# Example word indices (start and end positions of each word)\n",
    "# word_indices = [(0, 4), (5, 7), (8, 9), (10, 16), (17, 21), (22, 25), (26, 39), (40, 48)]\n",
    "\n",
    "# Extract words from text using indices\n",
    "# extracted_words = extract_words_from_indices(text, word_indices)\n",
    "\n",
    "# print(extracted_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "169b444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'niega\\t\\t[PREN]', 'incapacidad para\\t\\t[PREN]', 'negaitvo\\t\\t[PREN]', 'descartada\\t\\t[PREN]', 'afebril\\t\\t[POST]', 'ex\\t\\t[PREN]', 'negatiu\\t\\t[PREN]', 'exfumador\\t\\t[PREN]', 'negatividad\\t\\t[PREN]', 'sense\\t\\t[PREN]', 'inespecificos\\t\\t[PREN]', 'no\\t\\t[PREN]', 'retirar\\t\\t[PREN]', 'desaparicion de\\t\\t[PREN]', 'afebril\\t\\t[PREN]', 'sin\\t\\t[PREN]', 'negatividad del\\t\\t[PREN]', 'inespecifico\\t\\t[PREN]', 'negativas\\t\\t[PREN]', 'descarta\\t\\t[POST]', 'desorientado\\t\\t[PREN]', 'irregulares\\t\\t[POST]', 'negativo\\t\\t[PREN]', 'imposibilidad de\\t\\t[PREN]', 'negativa\\t\\t[PREN]', 'sin\\t\\t[POST]', 'falta de\\t\\t[PREN]', 'no\\t\\t[POST]', 'negativos\\t\\t[POST]', 'descarta\\t\\t[PREN]', 'suspendido\\t\\t[PREN]', 'ausencia de\\t\\t[POST]', 'se suspende\\t\\t[PREN]', 'se desestimo\\t\\t[PREN]', 'neg\\t\\t[PREN]', 'se retira\\t\\t[PREN]', 'ceden\\t\\t[PREN]', 'niegan\\t\\t[PREN]', 'en ninguna\\t\\t[PREN]', 'tampoco\\t\\t[PREN]', 'negatividad de\\t\\t[PREN]', 'inestabilidad\\t\\t[PREN]', 'indetectable\\t\\t[PREN]', 'retiro\\t\\t[PREN]', 'inespecifico\\t\\t[POST]', 'rechaza\\t\\t[PREN]', 'sense\\t\\t[POST]', 'ausencia\\t\\t[PREN]', 'desaparecen\\t\\t[PREN]', 'imposibilidad\\t\\t[POST]', 'negativas\\t\\t[POST]', 'ausencia de\\t\\t[PREN]', 'cede\\t\\t[PREN]', 'negativa\\t\\t[POST]', 'desaparicion del\\t\\t[PREN]', 'atipicos\\t\\t[POST]', 'ex fumador\\t\\t[PREN]', 'asintomatica\\t\\t[PREN]', 'negativo\\t\\t[POST]', 'negativos\\t\\t[PREN]', 'impide\\t\\t[PREN]', 'arritmicos\\t\\t[POST]', 'falta de\\t\\t[POST]', 'se retira\\t\\t[POST]', 'ninguno\\t\\t[PREN]', 'asintomatico\\t\\t[PREN]', 'nega\\t\\t[PREN]', 'neg\\t\\t[POST]', 'excepto\\t\\t[PREN]', 'desorientacion\\t\\t[PREN]'}\n",
      "{'aparentemente\\t\\tPSEU', 'sin aparente\\t\\tPSEU', 'se orienta\\t\\tPSEU', 'orientan como\\t\\tPSEU', 'no es posible descartar\\t\\tPSEU', 'sugiera de\\t\\tPSEU', 'dudosos\\t\\tPSEU', 'no parece\\t\\tPSEU', 'al parecer\\t\\tPSEU', 'valorar\\t\\tPSEU', 'clara\\t\\tPSEU', 'atribuida\\t\\tPSEU', 'desconocido\\t\\tPSEU', 'no clara\\t\\tPSEU', 'aparentes\\t\\tPSEU', 'sospechosa de\\t\\tPSEU', 'indiquen\\t\\tPSEU', 'poco porque\\t\\tPSEU', 'posibilidad de\\t\\tPSEU', 'permite descartar\\t\\tPSEU', 'posibles\\t\\tPSEU', 'indeterminado\\t\\tPSEU', 'aparente\\t\\tPSEU', 'sugestivos de\\t\\tPSEU', 'vs\\t\\tPSEU', 'se orientan\\t\\tPSEU', 'sin clara\\t\\tPSEU', 'sugiere\\t\\tPSEU', 'dudosa\\t\\tPSEU', 'posible\\t\\tPSEU', 'parece\\t\\tPSEU', 'puede\\t\\tPSEU', 'sospechosos de\\t\\tPSEU', 'sugieran\\t\\tPSEU', 'no permite descartar\\t\\tPSEU', 'sospecha\\t\\tPSEU', 'sospitosa de\\t\\tPSEU', 'impresiona\\t\\tPSEU', 'se desconoce\\t\\tPSEU', 'descartar\\t\\tPSEU', 'sospechan de\\t\\tPSEU', 'sugieren\\t\\tPSEU', 'probables\\t\\tPSEU', 'compatible amb\\t\\tPSEU', 'compatibles con\\t\\tPSEU', 'falsa\\t\\tPSEU', 'compatible\\t\\tPSEU', 'sugiriendo\\t\\tPSEU', 'sospechosas de\\t\\tPSEU', 'sugestivos con\\t\\tPSEU', 'plantea\\t\\tPSEU', 'podrian\\t\\tPSEU', 'sugestivas de\\t\\tPSEU', 'sin claras\\t\\tPSEU', 'impresiona de\\t\\tPSEU', 'compatible con\\t\\tPSEU', 'probablemente\\t\\tPSEU', 'posiblemente\\t\\tPSEU', 'dudoso\\t\\tPSEU', 'dudosamente\\t\\tPSEU', 'orienta como\\t\\tPSEU', 'ssospechosas de\\t\\tPSEU', 'sugestiva de\\t\\tPSEU', 'orientan\\t\\tPSEU', 'podria\\t\\tPSEU', 'no\\t\\tPSEU', 'desconoce\\t\\tPSEU', 'sugestivo de\\t\\tPSEU', 'sospecha de\\t\\tPSEU', 'dubtos\\t\\tPSEU', 'orienta\\t\\tPSEU', 'pudieran\\t\\tPSEU', 'sin\\t\\tPSEU', 'sin poder descartar\\t\\tPSEU', 'parecen\\t\\tPSEU', 'sin aparentes\\t\\tPSEU', 'interpreta\\t\\tPSEU', 'probable\\t\\tPSEU', 'sugestiva como\\t\\tPSEU'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "nega_word = []\n",
    "spec_word = []\n",
    "for inst in data:\n",
    "    # print(inst[\"data\"][\"text\"])\n",
    "    text = inst[\"data\"][\"text\"]\n",
    "    # print(\"-\"*10)\n",
    "    nega_temp = []\n",
    "    spec_temp = []\n",
    "    for index, j in enumerate(inst[\"predictions\"][0][\"result\"]):\n",
    "        # print(j)\n",
    "        # print(j[\"value\"][\"labels\"])\n",
    "        if(j[\"value\"][\"labels\"] == [\"NEG\"]):\n",
    "            negation = \"[PREN]\"\n",
    "            for k in range(index+1,len(inst[\"predictions\"][0][\"result\"])):\n",
    "                if(inst[\"predictions\"][0][\"result\"][k][\"value\"][\"labels\"] != [\"NSCO\"]):\n",
    "                    break\n",
    "                if(inst[\"predictions\"][0][\"result\"][k][\"value\"][\"start\"] <  j[\"value\"][\"start\"] and negation == \"[PREN]\"):\n",
    "                    negation = \"[POST]\"\n",
    "                #elif(inst[\"predictions\"][0][\"result\"][k][\"value\"][\"start\"] >  j[\"value\"][\"start\"] and negation == \"[POST]\"):\n",
    "                #    print(\"Error: we have scope before and after\")\n",
    "                #    aa = (j[\"value\"][\"start\"], j[\"value\"][\"end\"])\n",
    "                #    bb = inst[\"predictions\"][0][\"result\"]\n",
    "                #    print(f\"{aa} and index is {bb}\")\n",
    "                    \n",
    "            nega_temp.append(((j[\"value\"][\"start\"], j[\"value\"][\"end\"]),negation))\n",
    "        elif(j[\"value\"][\"labels\"] == [\"UNC\"]):\n",
    "            spec_temp.append(((j[\"value\"][\"start\"], j[\"value\"][\"end\"]),\"PSEU\"))\n",
    "    # print(nega_temp)\n",
    "    # print(spec_temp)\n",
    "    ne_word = extract_words_from_indices(text, nega_temp)\n",
    "    #print(ne_word)\n",
    "    nega_word.extend(ne_word)\n",
    "    spec_word.extend(extract_words_from_indices(text, spec_temp))\n",
    "    \n",
    "nega_word = set(nega_word)\n",
    "spec_word = set(spec_word)\n",
    "print(nega_word)\n",
    "print(spec_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03b880b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(word_list, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for word in word_list:\n",
    "            file.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b8e15827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the file to write to\n",
    "filename = '../data/negation_word.txt'\n",
    "\n",
    "# Call the function to write the list to the file\n",
    "write_list_to_file(nega_word, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01d4bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the file to write to\n",
    "filename = '../data/speculation_word.txt'\n",
    "\n",
    "# Call the function to write the list to the file\n",
    "write_list_to_file(spec_word, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82da69",
   "metadata": {},
   "source": [
    "### LIST OF MEDICAL TERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7a76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29417441",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.abspath(\"\"))\n",
    "train_data = load_tokens(os.path.join(ROOT_DIR, \"data\", \"training_data_tokens.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd13870",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter()\n",
    "\n",
    "for d in range(len(data)):\n",
    "\tdoc = data[d][\"predictions\"][0][\"result\"]\n",
    "\tfor s in range(len(doc)):\n",
    "\t\tsent = doc[s][\"value\"]\n",
    "\t\tif sent[\"labels\"] in [[\"NEG\"], [\"UNC\"]]:\n",
    "\t\t\tcontinue\n",
    "\t\tstart = sent[\"start\"]\n",
    "\t\tend = sent[\"end\"]\n",
    "\t\tcontext_words, _ = get_tokens(train_data[d], start, end)\n",
    "\t\twords.update(context_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1384ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted by frequency\n",
    "words_lst = sorted(words.items(), key=lambda x: x[1], reverse=True)\n",
    "words_lst = [word[0] for word in words_lst]\n",
    "words_lst = [word for word in words_lst if len(word) > 3] # heuristic to remove short words (medial terms are long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d90c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/medical_terms.txt'\n",
    "write_list_to_file(words_lst, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
